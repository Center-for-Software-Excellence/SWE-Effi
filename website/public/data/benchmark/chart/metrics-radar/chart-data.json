[
  {
    "metric": "Resolve Rate",
    "agentless-mini/Llama-3.3-70B-Instruct-FP8": "4.0",
    "agentless-mini/gpt-4o-mini-2024-07-18": "20",
    "agentless-mini/qwen3-32B": "28",
    "agentless/Llama-3.3-70B-Instruct-FP8": "28",
    "agentless/gpt-4o-mini-2024-07-18": "26",
    "agentless/qwen3-32B": "48",
    "auto-code-rover/Llama-3.3-70B-Instruct-FP8": "28",
    "auto-code-rover/gpt-4o-mini-2024-07-18": "12",
    "auto-code-rover/qwen3-32B": "38",
    "openhands/Llama-3.3-70B-Instruct-FP8": "20",
    "openhands/gpt-4o-mini-2024-07-18": "12",
    "openhands/qwen3-32B": "34",
    "swe-agent/Llama-3.3-70B-Instruct-FP8": "12",
    "swe-agent/gpt-4o-mini-2024-07-18": "10",
    "swe-agent/qwen3-32B": "28",
    "Min": 0,
    "Max": 100
  },
  {
    "metric": "Token Efficiency",
    "agentless-mini/Llama-3.3-70B-Instruct-FP8": "0.032",
    "agentless-mini/gpt-4o-mini-2024-07-18": "0.094",
    "agentless-mini/qwen3-32B": "0.22",
    "agentless/Llama-3.3-70B-Instruct-FP8": "0.48",
    "agentless/gpt-4o-mini-2024-07-18": "0.25",
    "agentless/qwen3-32B": "0.61",
    "auto-code-rover/Llama-3.3-70B-Instruct-FP8": "2.9",
    "auto-code-rover/gpt-4o-mini-2024-07-18": "0.88",
    "auto-code-rover/qwen3-32B": "0.60",
    "openhands/Llama-3.3-70B-Instruct-FP8": "4.4",
    "openhands/gpt-4o-mini-2024-07-18": "1.3",
    "openhands/qwen3-32B": "2.7",
    "swe-agent/Llama-3.3-70B-Instruct-FP8": "0.59",
    "swe-agent/gpt-4o-mini-2024-07-18": "21",
    "swe-agent/qwen3-32B": "2.8",
    "Min": 0,
    "Max": 100
  },
  {
    "metric": "Cost Efficiency",
    "agentless-mini/Llama-3.3-70B-Instruct-FP8": "0.0064",
    "agentless-mini/gpt-4o-mini-2024-07-18": "0.093",
    "agentless-mini/qwen3-32B": "0.16",
    "agentless/Llama-3.3-70B-Instruct-FP8": "0.068",
    "agentless/gpt-4o-mini-2024-07-18": "0.12",
    "agentless/qwen3-32B": "0.20",
    "auto-code-rover/Llama-3.3-70B-Instruct-FP8": "0.59",
    "auto-code-rover/gpt-4o-mini-2024-07-18": "0.84",
    "auto-code-rover/qwen3-32B": "0.45",
    "openhands/Llama-3.3-70B-Instruct-FP8": "0.92",
    "openhands/gpt-4o-mini-2024-07-18": "1.3",
    "openhands/qwen3-32B": "2.6",
    "swe-agent/Llama-3.3-70B-Instruct-FP8": "0.12",
    "swe-agent/gpt-4o-mini-2024-07-18": "21",
    "swe-agent/qwen3-32B": "2.6",
    "Min": 0,
    "Max": 100
  },
  {
    "metric": "Cpu Efficiency",
    "agentless-mini/Llama-3.3-70B-Instruct-FP8": "0.0056",
    "agentless-mini/gpt-4o-mini-2024-07-18": "0.020",
    "agentless-mini/qwen3-32B": "0.033",
    "agentless/Llama-3.3-70B-Instruct-FP8": "21",
    "agentless/gpt-4o-mini-2024-07-18": "29",
    "agentless/qwen3-32B": "54",
    "auto-code-rover/Llama-3.3-70B-Instruct-FP8": "0.52",
    "auto-code-rover/gpt-4o-mini-2024-07-18": "0.40",
    "auto-code-rover/qwen3-32B": "2.9",
    "openhands/Llama-3.3-70B-Instruct-FP8": "5.7",
    "openhands/gpt-4o-mini-2024-07-18": "1.5",
    "openhands/qwen3-32B": "6.5",
    "swe-agent/Llama-3.3-70B-Instruct-FP8": "0.35",
    "swe-agent/gpt-4o-mini-2024-07-18": "2.8",
    "swe-agent/qwen3-32B": "1.1",
    "Min": 0,
    "Max": 100
  },
  {
    "metric": "Inference Efficiency",
    "agentless-mini/Llama-3.3-70B-Instruct-FP8": "0.19",
    "agentless-mini/gpt-4o-mini-2024-07-18": "0.21",
    "agentless-mini/qwen3-32B": "5.6",
    "agentless/Llama-3.3-70B-Instruct-FP8": "15",
    "agentless/gpt-4o-mini-2024-07-18": "11",
    "agentless/qwen3-32B": "35",
    "auto-code-rover/Llama-3.3-70B-Instruct-FP8": "10",
    "auto-code-rover/gpt-4o-mini-2024-07-18": "4.3",
    "auto-code-rover/qwen3-32B": "14",
    "openhands/Llama-3.3-70B-Instruct-FP8": "5.3",
    "openhands/gpt-4o-mini-2024-07-18": "1.2",
    "openhands/qwen3-32B": "13",
    "swe-agent/Llama-3.3-70B-Instruct-FP8": "1.2",
    "swe-agent/gpt-4o-mini-2024-07-18": "21",
    "swe-agent/qwen3-32B": "23",
    "Min": 0,
    "Max": 100
  }
]